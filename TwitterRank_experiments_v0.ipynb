{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TwitterRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TwitterRank' from 'C:\\\\Users\\\\pradhyum\\\\github_repos\\\\TwitterRank\\\\TwitterRank.py'>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(TwitterRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('AI Twitter.csv',delimiter=',',skiprows=6,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query Id</th>\n",
       "      <th>Query Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Url</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Page Type</th>\n",
       "      <th>Language</th>\n",
       "      <th>...</th>\n",
       "      <th>Twitter Reply Count</th>\n",
       "      <th>Twitter Reply to</th>\n",
       "      <th>Twitter Retweet of</th>\n",
       "      <th>Twitter Retweets</th>\n",
       "      <th>Twitter Tweets</th>\n",
       "      <th>Twitter Verified</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>mozRank Score</th>\n",
       "      <th>Reach (new)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:59:13.0</td>\n",
       "      <td>SiRON Technologies Group Inc. (@ManagedbySiRON...</td>\n",
       "      <td>#RT MSCloud \"Learn how #AI offers new ways to ...</td>\n",
       "      <td>http://twitter.com/ManagedbySiRON/statuses/107...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2681</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:33:02.450+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:57.0</td>\n",
       "      <td>Roy Munin (@muninJLM): + local talent in AI, c...</td>\n",
       "      <td>+ local talent in AI, computer vision, visual ...</td>\n",
       "      <td>http://twitter.com/muninJLM/statuses/107590341...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>positive</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://twitter.com/muninJLM/statuses/107588714...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4685</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:31:31.330+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:24.0</td>\n",
       "      <td>Mcse.Carlos Barcia G (@carlosbarciag): RT @MSC...</td>\n",
       "      <td>RT @MSCloud: Learn how #AI offers new ways to ...</td>\n",
       "      <td>http://twitter.com/carlosbarciag/statuses/1075...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com/MSCloud/statuses/1075902673...</td>\n",
       "      <td>0</td>\n",
       "      <td>6417</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:33:02.450+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:23.0</td>\n",
       "      <td>Int Technology (@IntTechAU): MSCloud: Learn ho...</td>\n",
       "      <td>MSCloud: Learn how #AI offers new ways to boos...</td>\n",
       "      <td>http://twitter.com/IntTechAU/statuses/10759032...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7106</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:33:02.450+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:03.0</td>\n",
       "      <td>Dr N Patel üáÆüá≥ üö© (@hindustanse): RT @hindustans...</td>\n",
       "      <td>RT @hindustanse: @jeetensingh @RaiSahab20 @Sau...</td>\n",
       "      <td>http://twitter.com/hindustanse/statuses/107590...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com/hindustanse/statuses/107590...</td>\n",
       "      <td>0</td>\n",
       "      <td>470835</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T18:39:56.343+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>14736.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Query Id  Query Name                   Date  \\\n",
       "0  1999642147  AI Twitter  2018-12-20 23:59:13.0   \n",
       "1  1999642147  AI Twitter  2018-12-20 23:58:57.0   \n",
       "2  1999642147  AI Twitter  2018-12-20 23:58:24.0   \n",
       "3  1999642147  AI Twitter  2018-12-20 23:58:23.0   \n",
       "4  1999642147  AI Twitter  2018-12-20 23:58:03.0   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SiRON Technologies Group Inc. (@ManagedbySiRON...   \n",
       "1  Roy Munin (@muninJLM): + local talent in AI, c...   \n",
       "2  Mcse.Carlos Barcia G (@carlosbarciag): RT @MSC...   \n",
       "3  Int Technology (@IntTechAU): MSCloud: Learn ho...   \n",
       "4  Dr N Patel üáÆüá≥ üö© (@hindustanse): RT @hindustans...   \n",
       "\n",
       "                                             Snippet  \\\n",
       "0  #RT MSCloud \"Learn how #AI offers new ways to ...   \n",
       "1  + local talent in AI, computer vision, visual ...   \n",
       "2  RT @MSCloud: Learn how #AI offers new ways to ...   \n",
       "3  MSCloud: Learn how #AI offers new ways to boos...   \n",
       "4  RT @hindustanse: @jeetensingh @RaiSahab20 @Sau...   \n",
       "\n",
       "                                                 Url       Domain Sentiment  \\\n",
       "0  http://twitter.com/ManagedbySiRON/statuses/107...  twitter.com   neutral   \n",
       "1  http://twitter.com/muninJLM/statuses/107590341...  twitter.com  positive   \n",
       "2  http://twitter.com/carlosbarciag/statuses/1075...  twitter.com   neutral   \n",
       "3  http://twitter.com/IntTechAU/statuses/10759032...  twitter.com   neutral   \n",
       "4  http://twitter.com/hindustanse/statuses/107590...  twitter.com   neutral   \n",
       "\n",
       "  Page Type Language  ... Twitter Reply Count  \\\n",
       "0   twitter       en  ...                   0   \n",
       "1   twitter       en  ...                   0   \n",
       "2   twitter       en  ...                   0   \n",
       "3   twitter       en  ...                   0   \n",
       "4   twitter       en  ...                   0   \n",
       "\n",
       "                                    Twitter Reply to  \\\n",
       "0                                                NaN   \n",
       "1  http://twitter.com/muninJLM/statuses/107588714...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  Twitter Retweet of Twitter Retweets  \\\n",
       "0                                                NaN                0   \n",
       "1                                                NaN                0   \n",
       "2  http://twitter.com/MSCloud/statuses/1075902673...                0   \n",
       "3                                                NaN                0   \n",
       "4  http://twitter.com/hindustanse/statuses/107590...                0   \n",
       "\n",
       "  Twitter Tweets Twitter Verified                       Updated  Word Count  \\\n",
       "0           2681            False  2018-12-21T16:33:02.450+0000         NaN   \n",
       "1           4685            False  2018-12-21T16:31:31.330+0000         NaN   \n",
       "2           6417            False  2018-12-21T16:33:02.450+0000         NaN   \n",
       "3           7106            False  2018-12-21T16:33:02.450+0000         NaN   \n",
       "4         470835            False  2018-12-21T18:39:56.343+0000         NaN   \n",
       "\n",
       "  mozRank Score Reach (new)  \n",
       "0           9.6         0.0  \n",
       "1           9.6      1046.0  \n",
       "2           9.6         0.0  \n",
       "3           9.6         0.0  \n",
       "4           9.6     14736.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430895 entries, 0 to 430894\n",
      "Columns: 111 entries, Query Id to Reach (new)\n",
      "dtypes: bool(3), float64(21), int64(33), object(54)\n",
      "memory usage: 356.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Snippet', 'Url', 'Domain',\n",
       "       'Sentiment', 'Page Type', 'Language',\n",
       "       ...\n",
       "       'Twitter Reply Count', 'Twitter Reply to', 'Twitter Retweet of',\n",
       "       'Twitter Retweets', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Word Count', 'mozRank Score', 'Reach (new)'],\n",
       "      dtype='object', length=111)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\pradhyum\\appdata\\local\\programs\\python\\python35\\lib\\re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "#doc_list = TwitterRank.get_doc_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+ local talent in AI, computer vision, visual arts, architecture... #1 producer of CS students in the country and the most attractive brand is Intel/Mobileye so top students will definitely all check out Airbnb first before considering relocation for other corporates in TLV metro'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "tweets_df['Full Text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         #RT MSCloud \"Learn how #AI offers new ways to ...\n",
       "1         + local talent in AI, computer vision, visual ...\n",
       "2         RT @MSCloud: Learn how #AI offers new ways to ...\n",
       "3         MSCloud: Learn how #AI offers new ways to boos...\n",
       "4         RT @hindustanse: @jeetensingh @RaiSahab20 @Sau...\n",
       "5         RT @salilsethi: Dear 1 billion objects -\\n\\nI ...\n",
       "6         @jeetensingh @RaiSahab20 @SaundiD @kvQuote @Ra...\n",
       "7         RT @MHiesboeck: This @Google #AI created its o...\n",
       "8         RT @Office365: The #FutureOfWork is here. Read...\n",
       "9         Learn how #AI offers new ways to boost employe...\n",
       "10        RT @DingoPublishing: RT LeadHealthy: Feeling S...\n",
       "11        RT @GoogleARVR: AI is rapidly progressing, har...\n",
       "12        RT LeadHealthy: Feeling Stressed  at Work? üë©‚Äçüíº...\n",
       "13        RT @Adobe: Detect, tap and replicate. Watch as...\n",
       "14        RT @bzamayo: Machine learning and AI encompass...\n",
       "15        RT @LeadHealthy: Feeling Stressed  at Work? üë©‚Äç...\n",
       "16        RT @into_AI: A Year of AI Transformation - ......\n",
       "17        @Langsian1  Hi Langsian, You might be interest...\n",
       "18        Will AI takeover the world? Will Blockchain ch...\n",
       "19        @WhaleUpdate @hash278 @sXnyreh0Mpj4uuX @mislyv...\n",
       "20        Georgios Fradelos #company message Global 500 ...\n",
       "21        1. General Information for Deep Learning Funda...\n",
       "22        LMK what you think of my new app - Apple: -uss...\n",
       "23        RT @LeadHealthy: Feeling Stressed  at Work? üë©‚Äç...\n",
       "24        RT @blue_prism: #BluePrism2018: In March we un...\n",
       "25        RT @MikeQuindazzi: 4 advancing areas of #DeepL...\n",
       "26        RT @Ronald_vanLoon: How can organizations move...\n",
       "27        Microsoft publishes six principles to guide it...\n",
       "28        RT @NVIDIAEmbedded: Want a more technical dive...\n",
       "29        How Artificial Intelligence Will Change Corpor...\n",
       "                                ...                        \n",
       "430865    RT @RobinMazumder: @plragde @Twitter @jack as ...\n",
       "430866    @plragde @Twitter @jack as a computer science ...\n",
       "430867    RT @arnabch01: #AI #robotics #BigData #genomic...\n",
       "430868    RT @arnabch01: @semicvet50 @VladimerAntonov @M...\n",
       "430869    RT @bschorr: Microsoft and UPMC unveil virtual...\n",
       "430870    Three ways brands can benefit from adopting vo...\n",
       "430871    Some of the last interviews Instagram founder ...\n",
       "430872    Microsoft and UPMC unveil virtual AI assistant...\n",
       "430873    IBM is on a mission to defend its ‚Äòstreet cred...\n",
       "430874    Until data is misused, Facebook‚Äôs breach will ...\n",
       "430875    There are two important purchases you should m...\n",
       "430876    RT @wiwer77: Eight ways AI will change your bu...\n",
       "430877    RT @moipacheco: Today at work I built a #quadr...\n",
       "430878    To me selfie is the most offensive stuff you h...\n",
       "430879    RT @arnabch01: #AI #ML #Iot #robotics to usher...\n",
       "430880    RT @arnabch01: #AI #ML #BigData #HPC #robotics...\n",
       "430881    RT @arnabch01: The #World salutes #RobertKoch ...\n",
       "430882    RT @wiwer77: Going Beyond #Google: Are Search ...\n",
       "430883    RT @arnabch01: #AI #BigData #HPC t revolutioni...\n",
       "430884    RT @wiwer77: Until data is misused, #Facebook‚Äô...\n",
       "430885    RT @NBTech: Intel¬Æ FPGAs Powering Real-Time AI...\n",
       "430886    Microsoft has done a lot to encourage use of m...\n",
       "430887    RT @OracleServCloud: According to a new @Ovum ...\n",
       "430888    Microsoft has done a lot to encourage use of m...\n",
       "430889    RT @darrinpjohnson: Achieve up to 40x faster A...\n",
       "430890    RT @wiwer77: Developer Economics Survey: Data ...\n",
       "430891    RT @wiwer77: Sizing The Market Value Of Artifi...\n",
       "430892    Microsoft has done a lot to encourage use of m...\n",
       "430893    Strategic CHRO: Diane Gherson of IBM on How AI...\n",
       "430894    @Scale 2018 Keynote: Inside NVIDIA‚Äôs AI infras...\n",
       "Name: Full Text, Length: 430895, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweets_df['Full Text'].apply(lambda x:re.sub('[A-Za-z0-9]+\\.[A-Za-z0-9]+/[A-Za-z0-9.@]+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    tweet = re.sub('http\\S+','',tweet)\n",
    "    tweet = re.sub('(?!http://)bit.ly/\\S+','',tweet)\n",
    "    tweet = re.sub('[A-Za-z0-9.@]+\\.[A-Za-z0-9]+/[A-Za-z0-9.@]+','',tweet)\n",
    "    tweet = tweet.strip('[link]')\n",
    "    return tweet\n",
    "def extract_links(tweet):\n",
    "    link1 = re.findall('http\\S+',tweet)\n",
    "    return list(set(link1.extend(re.findall('(?!http://)bit.ly\\S+',tweet))))\n",
    "def remove_users(tweet):\n",
    "    tweet = re.sub('@[A-Za-z]+[A-Za-z0-9-_]','',tweet)\n",
    "    return tweet\n",
    "def remove_hashtags(tweet):\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)','', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "my_stopwords = nltk.corpus.stopwords.words('english')\n",
    "my_stopwords.append('rt')\n",
    "word_rooter = nltk.stem.snowball.PorterStemmer(ignore_stopwords=False).stem\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~‚Ä¢@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = remove_hashtags(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in nlp(tweet)\n",
    "                            if not nlp.vocab[word.text].is_stop] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word.lemma_ if '#' not in word.text else word\n",
    "                        for word in tweet_token_list] # apply lemmatization\n",
    "    if bigrams:\n",
    "        tweet_token_list = tweet_token_list+[tweet_token_list[i]+'_'+tweet_token_list[i+1]\n",
    "                                            for i in range(len(tweet_token_list)-1)]\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['Clean Tweet'] = tweets_df['Full Text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author')['Clean Tweet'].apply(lambda x:' '.join(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_, vocab, tf = TwitterRank.get_lda_model( samples=200, topics=10,n_iter=50, df_in=tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topics(algorithm, vocab, model_in=None):\n",
    "    if model_in is None:\n",
    "        if algorithm == 'LDA':\n",
    "            model = LatentDirichletAllocation(n_components=10)\n",
    "        elif algorithm == 'NMF':\n",
    "            model = NMF(n_components=10)\n",
    "        model.fit(tf)\n",
    "        model.get_params()\n",
    "    else: model = model_in\n",
    "    topic_word_df = pd.DataFrame(model.components_,columns=vocab)\n",
    "    sorted_topic_words = pd.DataFrame()\n",
    "    for index, row in topic_word_df.iterrows():\n",
    "        row_df = pd.DataFrame({'topic_'+str(index): row.sort_values(ascending=False).index[:5].values})\n",
    "        sorted_topic_words = pd.concat([sorted_topic_words,row_df],axis=1)\n",
    "    return topic_word_df, sorted_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_word, sorted_topic_words = model_topics('LDA',vocab=vocab,model_in=model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @salilsethi: Dear 1 billion objects -\\n\\nI see (and recognize) you.\\n\\nLove,\\nGoogle Lens\\n(circa 2018) \\n\\n#ai #google #machinelearning #googlelens #billionobjects #artificialintelligence #opticalcharacterrecognition #ocr #computervision\\n\\nturingtribe.com/story/google-l‚Ä¶'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#string_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://twitter.com/salilsethi/statuses/1075774605158113286'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#string = tweets_df['Twitter Retweet of'].iloc[5]\n",
    "#string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                       NaN\n",
       "1                                                       NaN\n",
       "2         http://twitter.com/MSCloud/statuses/1075902673...\n",
       "3                                                       NaN\n",
       "4         http://twitter.com/hindustanse/statuses/107590...\n",
       "5         http://twitter.com/salilsethi/statuses/1075774...\n",
       "6                                                       NaN\n",
       "7         http://twitter.com/MHiesboeck/statuses/1075885...\n",
       "8         http://twitter.com/Office365/statuses/10747306...\n",
       "9                                                       NaN\n",
       "10        http://twitter.com/DingoPublishing/statuses/10...\n",
       "11        http://twitter.com/GoogleARVR/statuses/1075549...\n",
       "12                                                      NaN\n",
       "13        http://twitter.com/Adobe/statuses/107555638887...\n",
       "14        http://twitter.com/bzamayo/statuses/1075900534...\n",
       "15        http://twitter.com/LeadHealthy/statuses/106816...\n",
       "16        http://twitter.com/into_AI/statuses/1075900883...\n",
       "17                                                      NaN\n",
       "18                                                      NaN\n",
       "19                                                      NaN\n",
       "20                                                      NaN\n",
       "21                                                      NaN\n",
       "22                                                      NaN\n",
       "23        http://twitter.com/LeadHealthy/statuses/106816...\n",
       "24        http://twitter.com/blue_prism/statuses/1075821...\n",
       "25        http://twitter.com/MikeQuindazzi/statuses/1075...\n",
       "26        http://twitter.com/Ronald_vanLoon/statuses/107...\n",
       "27                                                      NaN\n",
       "28        http://twitter.com/NVIDIAEmbedded/statuses/107...\n",
       "29                                                      NaN\n",
       "                                ...                        \n",
       "430865    http://twitter.com/RobinMazumder/statuses/1046...\n",
       "430866                                                  NaN\n",
       "430867    http://twitter.com/arnabch01/statuses/89657409...\n",
       "430868    http://twitter.com/arnabch01/statuses/10177332...\n",
       "430869    http://twitter.com/bschorr/statuses/1046552780...\n",
       "430870                                                  NaN\n",
       "430871                                                  NaN\n",
       "430872                                                  NaN\n",
       "430873                                                  NaN\n",
       "430874                                                  NaN\n",
       "430875                                                  NaN\n",
       "430876    http://twitter.com/wiwer77/statuses/1046539423...\n",
       "430877    http://twitter.com/moipacheco/statuses/1042152...\n",
       "430878                                                  NaN\n",
       "430879    http://twitter.com/arnabch01/statuses/88261549...\n",
       "430880    http://twitter.com/arnabch01/statuses/89964606...\n",
       "430881    http://twitter.com/arnabch01/statuses/93969788...\n",
       "430882    http://twitter.com/wiwer77/statuses/1046537092...\n",
       "430883    http://twitter.com/arnabch01/statuses/77855392...\n",
       "430884    http://twitter.com/wiwer77/statuses/1046534446...\n",
       "430885    http://twitter.com/NBTech/statuses/10465501258...\n",
       "430886                                                  NaN\n",
       "430887    http://twitter.com/OracleServCloud/statuses/10...\n",
       "430888                                                  NaN\n",
       "430889    http://twitter.com/darrinpjohnson/statuses/104...\n",
       "430890    http://twitter.com/wiwer77/statuses/1046535343...\n",
       "430891    http://twitter.com/wiwer77/statuses/1046353906...\n",
       "430892                                                  NaN\n",
       "430893                                                  NaN\n",
       "430894                                                  NaN\n",
       "Name: Twitter Retweet of, Length: 430895, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tweets_df['Twitter Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_retweet_of(tweet):\n",
    "    tweet = re.findall('(?<=http://twitter.com/)\\w+',tweet)[0]\n",
    "    return tweet\n",
    "tweets_df['Retweet of'] = tweets_df['Twitter Retweet of'].apply(lambda x:find_retweet_of(x) if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = nx.from_pandas_edgelist(tweets_df[tweets_df['Retweet of'].notna()],'Retweet of','Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.remove_nodes_from([i for i in list(G.nodes()) if i not in tweets_df['Author'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import csr_matrix, lil_matrix\n",
    "#adj = nx.to_scipy_sparse_matrix(G)\n",
    "#adj.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author').get_group('Kozinets')['Clean Tweet'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author').get_group('Kozinets')['Clean Tweet'].count()\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 80\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx_graph = TwitterRank.get_graph_object(tweets_df,filter_column='Retweet of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = pd.DataFrame(tweets_df[tweets_df['Retweet of'].isin(tweets_df['Author'].value_counts().index)].values, columns=tweets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes_to_remove = tweets_df['Retweet of'][~tweets_df['Retweet of'].isin(tweets_df['Author'].value_counts().index)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx_graph.remove_nodes_from(list(nodes_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ser = pd.Series(tweets_df['Author'].unique()).isin(pd.Series(nx_graph.nodes()))\n",
    "#ser[ser==False].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.drop([53440],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_list = TwitterRank.get_num_tweets_list(nx_graph,tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship = TwitterRank.get_relationship(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#friend_tweet_list = TwitterRank.get_friends_tweets_list(relationship, tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grouped tweets by user\n",
      "Creating term-author matrix\n",
      "Fitting LDA model to discover topics\n"
     ]
    }
   ],
   "source": [
    "model, vocab_list, term_frequency = TwitterRank.get_lda_model(5, 30, tweets_df)\n",
    "#dt = np.mat(model._unnormalized_transform(term_frequency))\n",
    "#row_normalized_dt = dt/np.sum(dt,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt = TwitterRank.get_Pt(1,tweets_list,friend_tweet_list,row_normalized_dt,relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Et = dt/np.sum(dt,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Et[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(TRt,index=nx_graph.nodes(),columns=['topic1 influence score']).sort_values(by='topic1 influence score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TwitterRank.get_TR_using_DT(dt, tweets_df, num_topics=5, gamma=0.2, tolerance=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_normalized_dt = dt/np.sum(dt,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TR_all = TwitterRank.get_TR(5 ,tweets_list, friend_tweet_list, row_normalized_dt, col_normalized_dt, relationship,\n",
    " #          gamma=0.2, tolerance=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TwitterRank.print_topics_as_df(model,vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grouped tweets by user\n",
      "Creating term-author matrix\n",
      "Fitting LDA model to discover topics\n",
      "Creating graph object\n",
      "Removing nodes where author doesn't exist in raw df\n",
      "Creating relationship matrix\n",
      "Gathering tweet count for all users\n",
      "Gathering tweet counts for friends of each user\n",
      "Ranking users by \n",
      "topic number 0\n",
      "Creating transition probability for topic 0\n",
      "Calculating influence scores for users under topic 0\n",
      "topic number 1\n",
      "Creating transition probability for topic 1\n",
      "Calculating influence scores for users under topic 1\n",
      "topic number 2\n",
      "Creating transition probability for topic 2\n",
      "Calculating influence scores for users under topic 2\n",
      "topic number 3\n",
      "Creating transition probability for topic 3\n",
      "Calculating influence scores for users under topic 3\n",
      "topic number 4\n",
      "Creating transition probability for topic 4\n",
      "Calculating influence scores for users under topic 4\n"
     ]
    }
   ],
   "source": [
    "TR, graph = TwitterRank.twitter_rank(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0Influncers</th>\n",
       "      <th>Topic1Influncers</th>\n",
       "      <th>Topic2Influncers</th>\n",
       "      <th>Topic3Influncers</th>\n",
       "      <th>Topic4Influncers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_Nhyira_</td>\n",
       "      <td>Edyard38308817</td>\n",
       "      <td>ellamas36678202</td>\n",
       "      <td>MarkSpencer</td>\n",
       "      <td>astrinity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zenithcoder</td>\n",
       "      <td>AndrewMDM</td>\n",
       "      <td>MissTyra_B</td>\n",
       "      <td>caligirl1909</td>\n",
       "      <td>MissTyra_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AlexanderDubas</td>\n",
       "      <td>MissTyra_B</td>\n",
       "      <td>oracleemeaps</td>\n",
       "      <td>dwschoenleber</td>\n",
       "      <td>AndrewMDM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GreenfinchTech</td>\n",
       "      <td>ftavcar</td>\n",
       "      <td>reighleyc</td>\n",
       "      <td>oryxchain2</td>\n",
       "      <td>MaBee_N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ammar_Haider</td>\n",
       "      <td>GreenfinchTech</td>\n",
       "      <td>lihairun</td>\n",
       "      <td>CommonFolksMan</td>\n",
       "      <td>V1ewF1nder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AndrewMDM</td>\n",
       "      <td>drctan</td>\n",
       "      <td>GonzaloOrtizLaz</td>\n",
       "      <td>ZohwaKarim</td>\n",
       "      <td>reighleyc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DrjoesmithJoe</td>\n",
       "      <td>fruity_priya</td>\n",
       "      <td>nishanil</td>\n",
       "      <td>CaitlinEHaynes</td>\n",
       "      <td>raschneiderman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DontMes77180322</td>\n",
       "      <td>CaitlinEHaynes</td>\n",
       "      <td>AndrewMDM</td>\n",
       "      <td>erica_pandey</td>\n",
       "      <td>WeWinningFr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>V1ewF1nder</td>\n",
       "      <td>SolignoMatilde</td>\n",
       "      <td>paolo_78</td>\n",
       "      <td>innomag_no</td>\n",
       "      <td>TheAkiru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fruity_priya</td>\n",
       "      <td>ALexandrrr84</td>\n",
       "      <td>keshengyu</td>\n",
       "      <td>Sinclair1182</td>\n",
       "      <td>ellamas36678202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic0Influncers Topic1Influncers Topic2Influncers Topic3Influncers  \\\n",
       "0         _Nhyira_   Edyard38308817  ellamas36678202      MarkSpencer   \n",
       "1      zenithcoder        AndrewMDM       MissTyra_B     caligirl1909   \n",
       "2   AlexanderDubas       MissTyra_B     oracleemeaps    dwschoenleber   \n",
       "3   GreenfinchTech          ftavcar        reighleyc       oryxchain2   \n",
       "4     Ammar_Haider   GreenfinchTech         lihairun   CommonFolksMan   \n",
       "5        AndrewMDM           drctan  GonzaloOrtizLaz       ZohwaKarim   \n",
       "6    DrjoesmithJoe     fruity_priya         nishanil   CaitlinEHaynes   \n",
       "7  DontMes77180322   CaitlinEHaynes        AndrewMDM     erica_pandey   \n",
       "8       V1ewF1nder   SolignoMatilde         paolo_78       innomag_no   \n",
       "9     fruity_priya     ALexandrrr84        keshengyu     Sinclair1182   \n",
       "\n",
       "  Topic4Influncers  \n",
       "0        astrinity  \n",
       "1       MissTyra_B  \n",
       "2        AndrewMDM  \n",
       "3          MaBee_N  \n",
       "4       V1ewF1nder  \n",
       "5        reighleyc  \n",
       "6   raschneiderman  \n",
       "7      WeWinningFr  \n",
       "8         TheAkiru  \n",
       "9  ellamas36678202  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ranks = TwitterRank.get_top_topic_influencers(TR,graph)\n",
    "final_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>googl</td>\n",
       "      <td>ai</td>\n",
       "      <td>gener</td>\n",
       "      <td>learn</td>\n",
       "      <td>regul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recognit</td>\n",
       "      <td>ibm</td>\n",
       "      <td>comput</td>\n",
       "      <td>machin</td>\n",
       "      <td>vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook</td>\n",
       "      <td>intellig</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>ai</td>\n",
       "      <td>want</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facial</td>\n",
       "      <td>artifici</td>\n",
       "      <td>use</td>\n",
       "      <td>googl</td>\n",
       "      <td>intel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>use</td>\n",
       "      <td>via</td>\n",
       "      <td>network</td>\n",
       "      <td>use</td>\n",
       "      <td>ye</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    topic_0   topic_1  topic_2 topic_3 topic_4\n",
       "0     googl        ai    gener   learn   regul\n",
       "1  recognit       ibm   comput  machin    vote\n",
       "2  facebook  intellig   nvidia      ai    want\n",
       "3    facial  artifici      use   googl   intel\n",
       "4       use       via  network     use      ye"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TwitterRank.print_topics_as_df(model,vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2       , 0.4       , 0.06666667, 0.33333333],\n",
       "       [0.31578947, 0.36842105, 0.15789474, 0.15789474],\n",
       "       [0.3       , 0.4       , 0.25      , 0.05      ],\n",
       "       [0.        , 0.125     , 0.125     , 0.75      ]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/a.sum(axis=1).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a/a.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
