{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\pradhyum\\\\github_repos\\\\TwitterRank_new')\n",
    "import TwitterRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('AI Twitter.csv',delimiter=',',skiprows=6,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    tweet = re.sub('http\\S+','',tweet)\n",
    "    tweet = re.sub('(?!http://)bit.ly/\\S+','',tweet)\n",
    "    tweet = re.sub('[A-Za-z0-9.@]+\\.[A-Za-z0-9]+/[A-Za-z0-9.@]+','',tweet)\n",
    "    tweet = tweet.strip('[link]')\n",
    "    return tweet\n",
    "def extract_links(tweet):\n",
    "    link1 = re.findall('http\\S+',tweet)\n",
    "    return list(set(link1.extend(re.findall('(?!http://)bit.ly\\S+',tweet))))\n",
    "def remove_users(tweet):\n",
    "    tweet = re.sub('@[A-Za-z]+[A-Za-z0-9-_]','',tweet)\n",
    "    return tweet\n",
    "def remove_hashtags(tweet):\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)','', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.Defaults.stop_words.add('rt')\n",
    "nlp.vocab['rt'].is_stop = True\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~â€¢@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = remove_hashtags(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in nlp(tweet)\n",
    "                            if not nlp.vocab[word.text].is_stop] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word.lemma_ if '#' not in word.text else word.text\n",
    "                        for word in tweet_token_list] # apply lemmatization\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['Clean Tweet'] = tweets_df['Full Text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topics(algorithm, vocab, model_in=None):\n",
    "    if model_in is None:\n",
    "        if algorithm == 'LDA':\n",
    "            model = LatentDirichletAllocation(n_components=10)\n",
    "        elif algorithm == 'NMF':\n",
    "            model = NMF(n_components=10)\n",
    "        model.fit(tf)\n",
    "        model.get_params()\n",
    "    else: model = model_in\n",
    "    topic_word_df = pd.DataFrame(model.components_,columns=vocab)\n",
    "    sorted_topic_words = pd.DataFrame()\n",
    "    for index, row in topic_word_df.iterrows():\n",
    "        row_df = pd.DataFrame({'topic_'+str(index): row.sort_values(ascending=False).index[:5].values})\n",
    "        sorted_topic_words = pd.concat([sorted_topic_words,row_df],axis=1)\n",
    "    return topic_word_df, sorted_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_retweet_of(tweet):\n",
    "    tweet = re.findall('(?<=http://twitter.com/)\\w+',tweet)[0]\n",
    "    return tweet\n",
    "tweets_df['Retweet of'] = tweets_df['Twitter Retweet of'].apply(lambda x:find_retweet_of(x) if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.to_csv('AI_twitter_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('AI_twitter_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = nx.from_pandas_edgelist(tweets_df[tweets_df['Retweet of'].notna()],'Retweet of','Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.remove_nodes_from([i for i in list(G.nodes()) if i not in tweets_df['Author'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import csr_matrix, lil_matrix\n",
    "#adj = nx.to_scipy_sparse_matrix(G)\n",
    "#adj.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author').get_group('Kozinets')['Clean Tweet'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author').get_group('Kozinets')['Clean Tweet'].count()\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 80\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx_graph = TwitterRank.get_graph_object(tweets_df,filter_column='Retweet of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = pd.DataFrame(tweets_df[tweets_df['Retweet of'].isin(tweets_df['Author'].value_counts().index)].values, columns=tweets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes_to_remove = tweets_df['Retweet of'][~tweets_df['Retweet of'].isin(tweets_df['Author'].value_counts().index)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx_graph.remove_nodes_from(list(nodes_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ser = pd.Series(tweets_df['Author'].unique()).isin(pd.Series(nx_graph.nodes()))\n",
    "#ser[ser==False].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.drop([53440],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_list = TwitterRank.get_num_tweets_list(nx_graph,tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship = TwitterRank.get_relationship(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#friend_tweet_list = TwitterRank.get_friends_tweets_list(relationship, tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, vocab_list, term_frequency = TwitterRank.get_lda_model(5, 30, tweets_df)\n",
    "#dt = np.mat(model._unnormalized_transform(term_frequency))\n",
    "#row_normalized_dt = dt/np.sum(dt,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt = TwitterRank.get_Pt(1,tweets_list,friend_tweet_list,row_normalized_dt,relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Et = dt/np.sum(dt,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Et[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(TRt,index=nx_graph.nodes(),columns=['topic1 influence score']).sort_values(by='topic1 influence score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TwitterRank.get_TR_using_DT(dt, tweets_df, num_topics=5, gamma=0.2, tolerance=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_normalized_dt = dt/np.sum(dt,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['Clean Tweet'] = tweets_df['Clean Tweet'].apply(lambda x:str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grouped tweets by user\n",
      "Creating term-author matrix\n",
      "Fitting LDA model to discover topics\n"
     ]
    }
   ],
   "source": [
    "model_, vocab_, tf_ = TwitterRank.get_lda_model(5,10,tweets_df)\n",
    "dt = model_._unnormalized_transform(tf_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating graph object\n",
      "Removing nodes where author doesn't exist in raw df\n",
      "Creating relationship matrix\n",
      "Gathering tweet count for all users\n",
      "Calculating influence scores for users under topic 0\n",
      "topic number 1\n",
      "Creating transition probability for topic 1\n",
      "Calculating influence scores for users under topic 1\n",
      "topic number 2\n",
      "Creating transition probability for topic 2\n",
      "Calculating influence scores for users under topic 2\n",
      "topic number 3\n",
      "Creating transition probability for topic 3\n",
      "Calculating influence scores for users under topic 3\n",
      "topic number 4\n",
      "Creating transition probability for topic 4\n",
      "Calculating influence scores for users under topic 4\n"
     ]
    }
   ],
   "source": [
    "TR, graph = TwitterRank.get_TR_using_DT(dt, tweets_df, 5, gamma=0.2, tolerance=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TR, graph, lda_model, lda_vocab = TwitterRank.twitter_rank(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic0Influncers</th>\n",
       "      <th>Topic1Influncers</th>\n",
       "      <th>Topic2Influncers</th>\n",
       "      <th>Topic3Influncers</th>\n",
       "      <th>Topic4Influncers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i_UCSY</td>\n",
       "      <td>FireTap_Digital</td>\n",
       "      <td>WitchyTheThird</td>\n",
       "      <td>onmedicglobal</td>\n",
       "      <td>matthewherper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>surajpramanik5</td>\n",
       "      <td>abhay16dec</td>\n",
       "      <td>Ohrkid</td>\n",
       "      <td>kbeguir</td>\n",
       "      <td>TeamATSG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mapanauta</td>\n",
       "      <td>Camtheagent</td>\n",
       "      <td>AyyoubAkbari</td>\n",
       "      <td>storytellr2002</td>\n",
       "      <td>Shwento</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TechWorldOracle</td>\n",
       "      <td>BrainCrumbz</td>\n",
       "      <td>arnaldoarnalm</td>\n",
       "      <td>cardiogalenico</td>\n",
       "      <td>abhay16dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AaceQatar</td>\n",
       "      <td>matthewherper</td>\n",
       "      <td>sloaneguy</td>\n",
       "      <td>abhay16dec</td>\n",
       "      <td>TrapObi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>azizakhan8</td>\n",
       "      <td>KayandNnn</td>\n",
       "      <td>stephenjaoates</td>\n",
       "      <td>_HeatherE</td>\n",
       "      <td>jmannteufel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hikarenchan</td>\n",
       "      <td>hellojabez</td>\n",
       "      <td>SPCOsandiego</td>\n",
       "      <td>ikoha254</td>\n",
       "      <td>KayandNnn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>matthewherper</td>\n",
       "      <td>TK_CH291</td>\n",
       "      <td>WaterSolarWind</td>\n",
       "      <td>RajenderSanti</td>\n",
       "      <td>AyyoubAkbari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OneGameDad</td>\n",
       "      <td>ZebraCakes</td>\n",
       "      <td>otonielgonca</td>\n",
       "      <td>ZebraCakes</td>\n",
       "      <td>Abbyroad713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>milancermak</td>\n",
       "      <td>mwesterl</td>\n",
       "      <td>DeannaBurgart</td>\n",
       "      <td>TK_CH291</td>\n",
       "      <td>JamesHubbard97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic0Influncers Topic1Influncers Topic2Influncers Topic3Influncers  \\\n",
       "0           i_UCSY  FireTap_Digital   WitchyTheThird    onmedicglobal   \n",
       "1   surajpramanik5       abhay16dec           Ohrkid          kbeguir   \n",
       "2        mapanauta      Camtheagent     AyyoubAkbari   storytellr2002   \n",
       "3  TechWorldOracle      BrainCrumbz    arnaldoarnalm   cardiogalenico   \n",
       "4        AaceQatar    matthewherper        sloaneguy       abhay16dec   \n",
       "5       azizakhan8        KayandNnn   stephenjaoates        _HeatherE   \n",
       "6      hikarenchan       hellojabez     SPCOsandiego         ikoha254   \n",
       "7    matthewherper         TK_CH291   WaterSolarWind    RajenderSanti   \n",
       "8       OneGameDad       ZebraCakes     otonielgonca       ZebraCakes   \n",
       "9      milancermak         mwesterl    DeannaBurgart         TK_CH291   \n",
       "\n",
       "  Topic4Influncers  \n",
       "0    matthewherper  \n",
       "1         TeamATSG  \n",
       "2          Shwento  \n",
       "3       abhay16dec  \n",
       "4          TrapObi  \n",
       "5      jmannteufel  \n",
       "6        KayandNnn  \n",
       "7     AyyoubAkbari  \n",
       "8      Abbyroad713  \n",
       "9   JamesHubbard97  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_ranks = TwitterRank.get_top_topic_influencers(TR,graph)\n",
    "final_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_0</th>\n",
       "      <th>topic_1</th>\n",
       "      <th>topic_2</th>\n",
       "      <th>topic_3</th>\n",
       "      <th>topic_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>face</td>\n",
       "      <td>machine</td>\n",
       "      <td>vote</td>\n",
       "      <td>ai</td>\n",
       "      <td>ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image</td>\n",
       "      <td>learn</td>\n",
       "      <td>recognition</td>\n",
       "      <td>google</td>\n",
       "      <td>ibm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>network</td>\n",
       "      <td>ai</td>\n",
       "      <td>intel</td>\n",
       "      <td>machine</td>\n",
       "      <td>google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>medium</td>\n",
       "      <td>google</td>\n",
       "      <td>want</td>\n",
       "      <td>microsoft</td>\n",
       "      <td>intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nvidia</td>\n",
       "      <td>learning</td>\n",
       "      <td>facial</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic_0   topic_1      topic_2       topic_3       topic_4\n",
       "0     face   machine         vote            ai            ai\n",
       "1    image     learn  recognition        google           ibm\n",
       "2  network        ai        intel       machine        google\n",
       "3   medium    google         want     microsoft  intelligence\n",
       "4   nvidia  learning       facial  intelligence    artificial"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = TwitterRank.print_topics_as_df(model_,vocab_)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from matplotlib import pylab\n",
    " import networkx as nx\n",
    "\n",
    " def save_graph(graph,file_name):\n",
    "    #initialze Figure\n",
    "    plt.figure(num=None, figsize=(20, 20), dpi=80)\n",
    "    plt.axis('off')\n",
    "    fig = plt.figure(1)\n",
    "    pos = nx.spring_layout(graph)\n",
    "    nx.draw_networkx_nodes(graph,pos)\n",
    "    nx.draw_networkx_edges(graph,pos)\n",
    "    nx.draw_networkx_labels(graph,pos)\n",
    "\n",
    "    cut = 1.00\n",
    "    xmax = cut * max(xx for xx, yy in pos.values())\n",
    "    ymax = cut * max(yy for xx, yy in pos.values())\n",
    "    plt.xlim(0, xmax)\n",
    "    plt.ylim(0, ymax)\n",
    "\n",
    "    plt.savefig(file_name,bbox_inches=\"tight\")\n",
    "    pylab.close()\n",
    "    del fig\n",
    "\n",
    "#Assuming that the graph g has nodes and edges entered\n",
    "save_graph(graph,\"my_graph.png\")\n",
    "\n",
    "#it can also be saved in .svg, .png. or .ps formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.subplots(figsize=(16,16))\n",
    "#nx.draw(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
