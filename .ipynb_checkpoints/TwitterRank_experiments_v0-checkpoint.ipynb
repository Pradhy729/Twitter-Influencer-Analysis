{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('C:\\\\Users\\\\pradhyum\\\\github_repos\\\\TwitterRank_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TwitterRank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'TwitterRank' from 'C:\\\\Users\\\\pradhyum\\\\github_repos\\\\TwitterRank_new\\\\TwitterRank.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(TwitterRank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.read_csv('AI Twitter.csv',delimiter=',',skiprows=6,error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query Id</th>\n",
       "      <th>Query Name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Snippet</th>\n",
       "      <th>Url</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Page Type</th>\n",
       "      <th>Language</th>\n",
       "      <th>...</th>\n",
       "      <th>Twitter Reply Count</th>\n",
       "      <th>Twitter Reply to</th>\n",
       "      <th>Twitter Retweet of</th>\n",
       "      <th>Twitter Retweets</th>\n",
       "      <th>Twitter Tweets</th>\n",
       "      <th>Twitter Verified</th>\n",
       "      <th>Updated</th>\n",
       "      <th>Word Count</th>\n",
       "      <th>mozRank Score</th>\n",
       "      <th>Reach (new)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:59:13.0</td>\n",
       "      <td>SiRON Technologies Group Inc. (@ManagedbySiRON...</td>\n",
       "      <td>#RT MSCloud \"Learn how #AI offers new ways to ...</td>\n",
       "      <td>http://twitter.com/ManagedbySiRON/statuses/107...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2681</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:33:02.450+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:57.0</td>\n",
       "      <td>Roy Munin (@muninJLM): + local talent in AI, c...</td>\n",
       "      <td>+ local talent in AI, computer vision, visual ...</td>\n",
       "      <td>http://twitter.com/muninJLM/statuses/107590341...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>positive</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>http://twitter.com/muninJLM/statuses/107588714...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4685</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:31:31.330+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:24.0</td>\n",
       "      <td>Mcse.Carlos Barcia G (@carlosbarciag): RT @MSC...</td>\n",
       "      <td>RT @MSCloud: Learn how #AI offers new ways to ...</td>\n",
       "      <td>http://twitter.com/carlosbarciag/statuses/1075...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com/MSCloud/statuses/1075902673...</td>\n",
       "      <td>0</td>\n",
       "      <td>6417</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:33:02.450+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:23.0</td>\n",
       "      <td>Int Technology (@IntTechAU): MSCloud: Learn ho...</td>\n",
       "      <td>MSCloud: Learn how #AI offers new ways to boos...</td>\n",
       "      <td>http://twitter.com/IntTechAU/statuses/10759032...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>7106</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T16:33:02.450+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1999642147</td>\n",
       "      <td>AI Twitter</td>\n",
       "      <td>2018-12-20 23:58:03.0</td>\n",
       "      <td>Dr N Patel ðŸ‡®ðŸ‡³ ðŸš© (@hindustanse): RT @hindustans...</td>\n",
       "      <td>RT @hindustanse: @jeetensingh @RaiSahab20 @Sau...</td>\n",
       "      <td>http://twitter.com/hindustanse/statuses/107590...</td>\n",
       "      <td>twitter.com</td>\n",
       "      <td>neutral</td>\n",
       "      <td>twitter</td>\n",
       "      <td>en</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://twitter.com/hindustanse/statuses/107590...</td>\n",
       "      <td>0</td>\n",
       "      <td>470835</td>\n",
       "      <td>False</td>\n",
       "      <td>2018-12-21T18:39:56.343+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>14736.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Query Id  Query Name                   Date  \\\n",
       "0  1999642147  AI Twitter  2018-12-20 23:59:13.0   \n",
       "1  1999642147  AI Twitter  2018-12-20 23:58:57.0   \n",
       "2  1999642147  AI Twitter  2018-12-20 23:58:24.0   \n",
       "3  1999642147  AI Twitter  2018-12-20 23:58:23.0   \n",
       "4  1999642147  AI Twitter  2018-12-20 23:58:03.0   \n",
       "\n",
       "                                               Title  \\\n",
       "0  SiRON Technologies Group Inc. (@ManagedbySiRON...   \n",
       "1  Roy Munin (@muninJLM): + local talent in AI, c...   \n",
       "2  Mcse.Carlos Barcia G (@carlosbarciag): RT @MSC...   \n",
       "3  Int Technology (@IntTechAU): MSCloud: Learn ho...   \n",
       "4  Dr N Patel ðŸ‡®ðŸ‡³ ðŸš© (@hindustanse): RT @hindustans...   \n",
       "\n",
       "                                             Snippet  \\\n",
       "0  #RT MSCloud \"Learn how #AI offers new ways to ...   \n",
       "1  + local talent in AI, computer vision, visual ...   \n",
       "2  RT @MSCloud: Learn how #AI offers new ways to ...   \n",
       "3  MSCloud: Learn how #AI offers new ways to boos...   \n",
       "4  RT @hindustanse: @jeetensingh @RaiSahab20 @Sau...   \n",
       "\n",
       "                                                 Url       Domain Sentiment  \\\n",
       "0  http://twitter.com/ManagedbySiRON/statuses/107...  twitter.com   neutral   \n",
       "1  http://twitter.com/muninJLM/statuses/107590341...  twitter.com  positive   \n",
       "2  http://twitter.com/carlosbarciag/statuses/1075...  twitter.com   neutral   \n",
       "3  http://twitter.com/IntTechAU/statuses/10759032...  twitter.com   neutral   \n",
       "4  http://twitter.com/hindustanse/statuses/107590...  twitter.com   neutral   \n",
       "\n",
       "  Page Type Language  ... Twitter Reply Count  \\\n",
       "0   twitter       en  ...                   0   \n",
       "1   twitter       en  ...                   0   \n",
       "2   twitter       en  ...                   0   \n",
       "3   twitter       en  ...                   0   \n",
       "4   twitter       en  ...                   0   \n",
       "\n",
       "                                    Twitter Reply to  \\\n",
       "0                                                NaN   \n",
       "1  http://twitter.com/muninJLM/statuses/107588714...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  Twitter Retweet of Twitter Retweets  \\\n",
       "0                                                NaN                0   \n",
       "1                                                NaN                0   \n",
       "2  http://twitter.com/MSCloud/statuses/1075902673...                0   \n",
       "3                                                NaN                0   \n",
       "4  http://twitter.com/hindustanse/statuses/107590...                0   \n",
       "\n",
       "  Twitter Tweets Twitter Verified                       Updated  Word Count  \\\n",
       "0           2681            False  2018-12-21T16:33:02.450+0000         NaN   \n",
       "1           4685            False  2018-12-21T16:31:31.330+0000         NaN   \n",
       "2           6417            False  2018-12-21T16:33:02.450+0000         NaN   \n",
       "3           7106            False  2018-12-21T16:33:02.450+0000         NaN   \n",
       "4         470835            False  2018-12-21T18:39:56.343+0000         NaN   \n",
       "\n",
       "  mozRank Score Reach (new)  \n",
       "0           9.6         0.0  \n",
       "1           9.6      1046.0  \n",
       "2           9.6         0.0  \n",
       "3           9.6         0.0  \n",
       "4           9.6     14736.0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 430895 entries, 0 to 430894\n",
      "Columns: 111 entries, Query Id to Reach (new)\n",
      "dtypes: bool(3), float64(21), int64(33), object(54)\n",
      "memory usage: 356.3+ MB\n"
     ]
    }
   ],
   "source": [
    "tweets_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Snippet', 'Url', 'Domain',\n",
       "       'Sentiment', 'Page Type', 'Language',\n",
       "       ...\n",
       "       'Twitter Reply Count', 'Twitter Reply to', 'Twitter Retweet of',\n",
       "       'Twitter Retweets', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Word Count', 'mozRank Score', 'Reach (new)'],\n",
       "      dtype='object', length=111)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_list = TwitterRank.get_doc_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+ local talent in AI, computer vision, visual arts, architecture... #1 producer of CS students in the country and the most attractive brand is Intel/Mobileye so top students will definitely all check out Airbnb first before considering relocation for other corporates in TLV metro'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "tweets_df['Full Text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Full Text'].apply(lambda x:re.sub('[A-Za-z0-9]+\\.[A-Za-z0-9]+/[A-Za-z0-9.@]+','',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_links(tweet):\n",
    "    tweet = re.sub('http\\S+','',tweet)\n",
    "    tweet = re.sub('(?!http://)bit.ly/\\S+','',tweet)\n",
    "    tweet = re.sub('[A-Za-z0-9.@]+\\.[A-Za-z0-9]+/[A-Za-z0-9.@]+','',tweet)\n",
    "    tweet = tweet.strip('[link]')\n",
    "    return tweet\n",
    "def extract_links(tweet):\n",
    "    link1 = re.findall('http\\S+',tweet)\n",
    "    return list(set(link1.extend(re.findall('(?!http://)bit.ly\\S+',tweet))))\n",
    "def remove_users(tweet):\n",
    "    tweet = re.sub('@[A-Za-z]+[A-Za-z0-9-_]','',tweet)\n",
    "    return tweet\n",
    "def remove_hashtags(tweet):\n",
    "    tweet = re.sub('(#[A-Za-z]+[A-Za-z0-9-_]+)','', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.Defaults.stop_words.add('rt')\n",
    "nlp.vocab['rt'].is_stop = True\n",
    "my_punctuation = '!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~â€¢@'\n",
    "\n",
    "# cleaning master function\n",
    "def clean_tweet(tweet, bigrams=False):\n",
    "    tweet = remove_users(tweet)\n",
    "    tweet = remove_links(tweet)\n",
    "    tweet = remove_hashtags(tweet)\n",
    "    tweet = tweet.lower() # lower case\n",
    "    tweet = re.sub('['+my_punctuation + ']+', ' ', tweet) # strip punctuation\n",
    "    tweet = re.sub('\\s+', ' ', tweet) #remove double spacing\n",
    "    tweet = re.sub('([0-9]+)', '', tweet) # remove numbers\n",
    "    tweet_token_list = [word for word in nlp(tweet)\n",
    "                            if not nlp.vocab[word.text].is_stop] # remove stopwords\n",
    "\n",
    "    tweet_token_list = [word.lemma_ if '#' not in word.text else word.text\n",
    "                        for word in tweet_token_list] # apply lemmatization\n",
    "    tweet = ' '.join(tweet_token_list)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['Clean Tweet'] = tweets_df['Full Text'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author')['Clean Tweet'].apply(lambda x:' '.join(x)).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_, vocab, tf = TwitterRank.get_lda_model( samples=200, topics=10,n_iter=50, df_in=tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_topics(algorithm, vocab, model_in=None):\n",
    "    if model_in is None:\n",
    "        if algorithm == 'LDA':\n",
    "            model = LatentDirichletAllocation(n_components=10)\n",
    "        elif algorithm == 'NMF':\n",
    "            model = NMF(n_components=10)\n",
    "        model.fit(tf)\n",
    "        model.get_params()\n",
    "    else: model = model_in\n",
    "    topic_word_df = pd.DataFrame(model.components_,columns=vocab)\n",
    "    sorted_topic_words = pd.DataFrame()\n",
    "    for index, row in topic_word_df.iterrows():\n",
    "        row_df = pd.DataFrame({'topic_'+str(index): row.sort_values(ascending=False).index[:5].values})\n",
    "        sorted_topic_words = pd.concat([sorted_topic_words,row_df],axis=1)\n",
    "    return topic_word_df, sorted_topic_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topics_word, sorted_topic_words = model_topics('LDA',vocab=vocab,model_in=model_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string = tweets_df['Twitter Retweet of'].iloc[5]\n",
    "#string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Twitter Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_retweet_of(tweet):\n",
    "    tweet = re.findall('(?<=http://twitter.com/)\\w+',tweet)[0]\n",
    "    return tweet\n",
    "tweets_df['Retweet of'] = tweets_df['Twitter Retweet of'].apply(lambda x:find_retweet_of(x) if not pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df['Retweet of']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G = nx.from_pandas_edgelist(tweets_df[tweets_df['Retweet of'].notna()],'Retweet of','Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#G.remove_nodes_from([i for i in list(G.nodes()) if i not in tweets_df['Author'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.sparse import csr_matrix, lil_matrix\n",
    "#adj = nx.to_scipy_sparse_matrix(G)\n",
    "#adj.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author').get_group('Kozinets')['Clean Tweet'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.groupby('Author').get_group('Kozinets')['Clean Tweet'].count()\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 80\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length * progress))\n",
    "\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx_graph = TwitterRank.get_graph_object(tweets_df,filter_column='Retweet of')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df = pd.DataFrame(tweets_df[tweets_df['Retweet of'].isin(tweets_df['Author'].value_counts().index)].values, columns=tweets_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nodes_to_remove = tweets_df['Retweet of'][~tweets_df['Retweet of'].isin(tweets_df['Author'].value_counts().index)].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nx_graph.remove_nodes_from(list(nodes_to_remove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ser = pd.Series(tweets_df['Author'].unique()).isin(pd.Series(nx_graph.nodes()))\n",
    "#ser[ser==False].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df.drop([53440],axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_list = TwitterRank.get_num_tweets_list(nx_graph,tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#relationship = TwitterRank.get_relationship(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#friend_tweet_list = TwitterRank.get_friends_tweets_list(relationship, tweets_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, vocab_list, term_frequency = TwitterRank.get_lda_model(5, 30, tweets_df)\n",
    "#dt = np.mat(model._unnormalized_transform(term_frequency))\n",
    "#row_normalized_dt = dt/np.sum(dt,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pt = TwitterRank.get_Pt(1,tweets_list,friend_tweet_list,row_normalized_dt,relationship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Et = dt/np.sum(dt,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Et[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(TRt,index=nx_graph.nodes(),columns=['topic1 influence score']).sort_values(by='topic1 influence score',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TwitterRank.get_TR_using_DT(dt, tweets_df, num_topics=5, gamma=0.2, tolerance=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col_normalized_dt = dt/np.sum(dt,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TR_all = TwitterRank.get_TR(5 ,tweets_list, friend_tweet_list, row_normalized_dt, col_normalized_dt, relationship,\n",
    " #          gamma=0.2, tolerance=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TwitterRank.print_topics_as_df(model,vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grouped tweets by user\n",
      "Creating term-author matrix\n",
      "Fitting LDA model to discover topics\n"
     ]
    }
   ],
   "source": [
    "TR, graph, lda_model, lda_vocab = TwitterRank.twitter_rank(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranks = TwitterRank.get_top_topic_influencers(TR,graph)\n",
    "final_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TwitterRank.print_topics_as_df(lda_model,lda_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " from matplotlib import pylab\n",
    " import networkx as nx\n",
    "\n",
    " def save_graph(graph,file_name):\n",
    "    #initialze Figure\n",
    "    plt.figure(num=None, figsize=(20, 20), dpi=80)\n",
    "    plt.axis('off')\n",
    "    fig = plt.figure(1)\n",
    "    pos = nx.spring_layout(graph)\n",
    "    nx.draw_networkx_nodes(graph,pos)\n",
    "    nx.draw_networkx_edges(graph,pos)\n",
    "    nx.draw_networkx_labels(graph,pos)\n",
    "\n",
    "    cut = 1.00\n",
    "    xmax = cut * max(xx for xx, yy in pos.values())\n",
    "    ymax = cut * max(yy for xx, yy in pos.values())\n",
    "    plt.xlim(0, xmax)\n",
    "    plt.ylim(0, ymax)\n",
    "\n",
    "    plt.savefig(file_name,bbox_inches=\"tight\")\n",
    "    pylab.close()\n",
    "    del fig\n",
    "\n",
    "#Assuming that the graph g has nodes and edges entered\n",
    "save_graph(graph,\"my_graph.png\")\n",
    "\n",
    "#it can also be saved in .svg, .png. or .ps formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
